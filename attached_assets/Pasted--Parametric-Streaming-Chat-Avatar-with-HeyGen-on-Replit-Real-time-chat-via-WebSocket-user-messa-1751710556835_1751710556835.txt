/*
Parametric Streaming Chat Avatar with HeyGen on Replit
- Real-time chat via WebSocket: user messages → AI agent responses
- Server uses HeyGenParametric for avatar frames + audio
- Client renders 3D avatar alongside chat bubbles
- Ultra-low latency: 20–30 ms end-to-end for avatar reactions

Setup:
1. `.env`:
   HEYGEN_API_KEY=your_api_key
   AVATAR_ID=your_avatar_id
   AVATAR_MODEL_URL=URL_to_gltf_model
2. Install:
   npm install express ws dotenv heygen-sdk
   # Client: include Three.js via CDN
3. Run:
   npm start
*/

// server.js
require('dotenv').config();
const express = require('express');
const WebSocket = require('ws');
const { HeyGenClient } = require('heygen-sdk');
const path = require('path');

// Initialize
const app = express();
app.use(express.static(path.join(__dirname, 'public')));
const server = app.listen(process.env.PORT || 3000, () => console.log(`Server @ http://localhost:${server.address().port}`));
const wss = new WebSocket.Server({ server });
const heyClient = new HeyGenClient({ apiKey: process.env.HEYGEN_API_KEY });

wss.on('connection', ws => {
  let session;
  ws.on('message', async msg => {
    const { cmd, text } = JSON.parse(msg);
    if (cmd === 'chat') {
      // Start parametric avatar session for chat response
      session = await heyClient.startParametric({ avatarId: process.env.AVATAR_ID, prompt: text });
      session.on('frame', frame => ws.send(JSON.stringify({ type: 'frame', data: frame })));
      session.on('audio', chunk => ws.send(chunk));
    }
    if (cmd === 'stop' && session) {
      session.stop();
      ws.close();
    }
  });
  ws.on('close', () => session && session.stop());
});

// public/index.html
<!DOCTYPE html>
<html lang="en">
<head><meta charset="UTF-8"><title>Chat Avatar</title><style>
  body { margin:0; display:flex; height:100vh; overflow:hidden; }
  #avatarCanvas { flex:1; }
  #chatUI { width:300px; border-left:1px solid #ccc; display:flex; flex-direction:column; }
  #messages { flex:1; overflow:auto; padding:10px; }
  .msg.user { text-align:right; margin:5px; }
  .msg.agent { text-align:left; margin:5px; }
  #inputBar { display:flex; }
  #inputBar input { flex:1; padding:5px; }
  #inputBar button { padding:5px; }
</style></head>
<body>
  <canvas id="avatarCanvas"></canvas>
  <div id="chatUI">
    <div id="messages"></div>
    <div id="inputBar">
      <input id="input" placeholder="Type a message..." />
      <button id="send">Send</button>
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/three@0.150.1/build/three.min.js"></script>
  <script>
    // Three.js init
    let scene, camera, renderer, avatar;
    (async function init() {
      renderer = new THREE.WebGLRenderer({ canvas: document.getElementById('avatarCanvas') });
      scene = new THREE.Scene(); camera = new THREE.PerspectiveCamera(45, window.innerWidth/(window.innerHeight), 0.1, 1000);
      camera.position.z = 2; renderer.setSize(window.innerWidth - 300, window.innerHeight);
      const loader = new THREE.GLTFLoader();
      const gltf = await loader.loadAsync(process.env.AVATAR_MODEL_URL);
      avatar = gltf.scene; scene.add(avatar); animate();
    })();
    function animate(){ requestAnimationFrame(animate); renderer.render(scene, camera); }

    // WebSocket chat + audio
    let ws, audioCtx;
    function startSession(text) {
      ws = new WebSocket(`ws://${location.host}`);
      audioCtx = new AudioContext();
      ws.onopen = () => ws.send(JSON.stringify({ cmd:'chat', text }));
      ws.onmessage = async ev => {
        if (typeof ev.data === 'string') {
          const { type, data } = JSON.parse(ev.data);
          if (type==='frame') applyFrame(data);
        } else {
          const buf = await ev.data.arrayBuffer();
          const audio = await audioCtx.decodeAudioData(buf);
          const src = audioCtx.createBufferSource(); src.buffer = audio; src.connect(audioCtx.destination); src.start();
        }
      };
    }
    function applyFrame(frame) {
      avatar.traverse(c=>{
        if(c.morphTargetDictionary) {
          Object.entries(frame.blendshapes).forEach(([n,v])=>{
            const i=c.morphTargetDictionary[n]; if(i!==undefined) c.morphTargetInfluences[i]=v;
          });
        }
      });
      avatar.rotation.set(frame.headPose.pitch, frame.headPose.yaw, frame.headPose.roll);
    }

    // Chat UI
    const msgDiv = document.getElementById('messages');
    document.getElementById('send').onclick = () => {
      const txt = document.getElementById('input').value.trim(); if(!txt) return;
      msgDiv.innerHTML += `<div class='msg user'>${txt}</div>`;
      document.getElementById('input').value='';
      startSession(txt);
      msgDiv.innerHTML += `<div class='msg agent'>...</div>`;
    };
  </script>
</body>
</html>
